{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un'analisi IRT dei quesiti del Bebras italiano\n",
    "\n",
    "L'*Item Response Theory* (IRT) è una tecnica statistica che si propone di stimare l'*abilità* dei soggetti cui viene sottoposto un test composto da una serie di domande (dette *item*). L'abilità è un tratto *latente*, cioè non osservabile direttamente: l'aver risposto correttamente a molte domande può dipendere sia da elevata abilità, che dalla \"facilità\" delle domande. La stima si basa quindi su un *modello matematico* (detto *Item Response Function*) della relazione fra abilità e probabilità di rispondere correttamente alla domanda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello usato in questa analisi è una curva *logistica*, la cui forma è regolata da tre parametri $a, b, c$.\n",
    "$$ p_i(\\theta_j) = c_i + \\frac{(1 - c_i)}{1+ e^{-b_i\\cdot(\\theta_j - a_i)}} $$\n",
    "La probabilità $p$ di successo in un *item* $i$ è funzione dell'abilità $\\theta$ del solutore $j$. I tre parametri modellano le caratteristiche dell'*item*:\n",
    "- $a$, detto *difficoltà* dell'item: determina il livello di abilità necessaria per avere il 50% di probabilità di successo;\n",
    "- $b$, detto *differenziazione*: determina quanto influiscono le variazioni di abilità sulla probabilità di successo;\n",
    "- $c$: fissa una probabilità minima di successo per qualsiasi abilità, dovuta per esempio alla possibilità di scegliere casualmente la risposta giusta ($c$ sarà 0 per un *item* a risposta completamente aperta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic <- function(theta, a=0, b=1, c=0) { \n",
    "    c + (1-c)/(1 + exp(-b*(theta-a)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(\"ggplot2\")\n",
    "data <- data.frame(x=seq(-5,5,.1))\n",
    "data <- transform(data, \n",
    "                  y_mean = logistic(x), \n",
    "                  y_hard = logistic(x,a=2), \n",
    "                  y_easy=logistic(x,a=-2),\n",
    "                  y_hdiscrimination=logistic(x,b=2),\n",
    "                  y_ldiscrimination=logistic(x,b=.5)\n",
    "                 );\n",
    "\n",
    "options(repr.plot.width=6, repr.plot.height=6)\n",
    "p <- ggplot(data, aes(x=x))\n",
    "p <- p + scale_x_continuous()\n",
    "p <- p + geom_hline(yintercept=0.5, linetype=\"dashed\")\n",
    "p <- p + geom_line(aes(y=y_hard), color=\"red\")\n",
    "p <- p + annotate(\"text\", x=2.1, y=.55, label=\"a == 2 ~~(plain(difficile))\", parse=TRUE, color=\"red\")\n",
    "p <- p + geom_line(aes(y=y_easy), color=\"dark green\")\n",
    "p <- p + annotate(\"text\", x=-1.9, y=.55, label=\"a == -2 ~~(plain(facile))\", parse=TRUE, color=\"dark green\")\n",
    "p <- p + geom_line(aes(y=y_mean), color=\"blue\")\n",
    "p <- p + annotate(\"text\", x=1.5, y=.8, label=\"a == 0 ~~(plain(medio))\", parse=TRUE, color=\"blue\")\n",
    "p <- p + geom_line(aes(y=y_hdiscrimination), color=\"dark cyan\")\n",
    "p <- p + annotate(\"text\", x=1, y=.9, label=\"a == 0 ~~ b == 2\", parse=TRUE, color=\"dark cyan\")\n",
    "p <- p + geom_line(aes(y=y_ldiscrimination), color=\"violet\")\n",
    "p <- p + annotate(\"text\", x=1.8, y=.7, label=\"a == 0 ~~ b == .5\", parse=TRUE, color=\"violet\")\n",
    "p <- p + labs(title=expression(paste(\"Curve logistiche per diversi valori di \", a, \" e \", b, \" (\",c==0,\")\")), \n",
    "              x=\"Abilità\", y=\"Probabilità di successo\")\n",
    "\n",
    "ggsave(filename = 'logistic.png', plot = p, width = 6, height = 6)\n",
    "rm(data, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logistic](logistic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ogni *item* o quiz, quindi, viene associata una specifica curva logistica (la sua *item response function*) che può essere dedotta osservando un campione di risolutori cui è stato sottoposto il test. A questo scopo i parametri relativi ai quiz del Bebras italiano 2015 sono stati stimati con un approccio bayesiano, come descritto in [C. Bellettini et al. *\"How challenging are Bebras tasks? an IRT analysis based on the performance of Italian students\", Proceedings of the 20th annual conference on innovation and technology in computer science education ITiCSE'15* (Vilnius, Lithuania, 2015)](http://dx.doi.org/10.1145/2729094.2742603). I dettagli statistici riguardo la bontà di adattamento del modello sono disponibili [qui](https://mmonga.shinyapps.io/bebrasIT2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I quesiti 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "rstan (Version 2.8.0, packaged: 2015-09-19 14:48:38 UTC, GitRev: 05c3d0058b6a)\n",
      "For execution on a local, multicore CPU with excess RAM we recommend calling\n",
      "rstan_options(auto_write = TRUE)\n",
      "options(mc.cores = parallel::detectCores())\n"
     ]
    }
   ],
   "source": [
    "library(\"rstan\"); rstan_options(auto_write = TRUE); options(mc.cores = parallel::detectCores())\n",
    "load(\"fit.RData\") # carica l'oggetto fit\n",
    "dfit <- as.data.frame(fit)\n",
    "obs <- read_rdump(\"bebras-all.data.R\")\n",
    "source(\"qnames.R\")\n",
    "\n",
    "cats <- c(\"kilo\", \"mega\", \"giga\", \"tera\", \"peta\")\n",
    "categories <- factor(cats, levels=cats, ordered = TRUE)\n",
    "rm(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dfit` è il data frame che raccoglie l'esito della simulazione, con 3394 variabili (3168 *ability*, 75 *discrimination*, 75 *difficulty*, 75 *guessing* e la logprobability) e 2000 campioni. `obs` è la lista dei dati effettivamente osservati, cioè 47520 risposte di 3168 squadre a 75 quiz, con 5 categorie. `qnames` contiene i nomi completi dei quiz, come `'2015_Kilo_A1_HU02_Apparecchiare'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs$rcats <- plyr::aaply(obs$rquiz, 1, function (e){ as.character(categories[ ((e - 1) %/% 15) + 1 ]) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:plyr’:\n",
      "\n",
      "    arrange, count, desc, failwith, id, mutate, rename, summarise,\n",
      "    summarize\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(\"plyr\")\n",
    "library(\"dplyr\")\n",
    "teams <- data.frame(id = obs$rtaker, category = obs$rcats) %>% distinct()\n",
    "get_par_df <- function(df, par, table) {\n",
    "    df %>% \n",
    "    dplyr::select(contains(par)) %>% \n",
    "    tidyr::gather(key = \"parameter\", value, everything()) %>%\n",
    "    dplyr::mutate(\"id\" = as.numeric(regmatches(parameter, regexpr(\"[0-9]+\",parameter)))) %>%\n",
    "    dplyr::left_join(table, by = \"id\") %>%\n",
    "    transform(category = factor(category, levels=levels(categories), ordered = TRUE))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "team_ability <- get_par_df(dfit, \"ability\", teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello è tarato in modo che la media delle abilità di tutte le squadre partecipanti sia 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Min.                   1st Qu.                    Median \n",
      "                   -5.616                   -0.7227                  0.002395 \n",
      "                     Mean                   3rd Qu.                      Max. \n",
      "               -3.509e-17                    0.7237                     5.662 \n",
      "                          \n",
      "StdDev:  1.07960634648982 \n"
     ]
    }
   ],
   "source": [
    "print(c(summary(team_ability$value), paste(\"StdDev: \", sd(team_ability$value))), quote = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "team_ability.notes <- ddply(team_ability, .(category), summarise, note=sprintf(\"paste(mu == %s, ' ', sigma == %s)\", \n",
    "                                                                     format(mean(value), digit = 2), \n",
    "                                                                     format(sd(value), digit= 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=10, repr.plot.height=2)\n",
    "p <- ggplot(team_ability, aes(x=value)) \n",
    "p <- p + geom_histogram(binwidth=.2) + coord_cartesian(ylim = c(0,.5))\n",
    "p <- p + aes(y=..density..)\n",
    "p <- p + facet_grid(. ~ category)\n",
    "p <- p + geom_text(data=team_ability.notes, aes(0, 0.4, label=note), size=3, parse = TRUE)\n",
    "p <- p + labs(title=\"Distribuzione dell'abilità dei partecipanti\", \n",
    "              x=\"Abilità\", y=\"Densità\")\n",
    "ggsave(filename = 'team_ability.png', plot = p, width = 10, height = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![team_ability](team_ability.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qorder <- plyr::laply(strsplit(qnames, \"_\"), function(e){e[3]})\n",
    "quizzes <- data.frame(id = 1:length(qnames), quiz = qnames, \n",
    "                      category = factor(plyr::laply(strsplit(qnames, \"_\"), function(e){tolower(e[2])}), \n",
    "                                        levels=levels(categories), ordered = TRUE),\n",
    "                      qname = plyr::laply(strsplit(qnames, \"_\"), function(e){e[5]}),\n",
    "                      bebras_id = plyr::laply(strsplit(qnames, \"_\"), function(e){e[4]}),\n",
    "                      ord = factor(qorder, levels=rev(sort(unique(qorder))), ordered = TRUE),\n",
    "                      country = plyr::laply(strsplit(qnames, \"_\"), function(e){substr(e[4],1,2)}),\n",
    "                      block = plyr::laply(strsplit(qnames, \"_\"), function(e){substr(e[3],1,1)}))\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quiz_difficulty <- get_par_df(dfit, par = \"difficulty\", table = quizzes)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=10, repr.plot.height=10)\n",
    "p <- ggplot(quiz_difficulty, aes(ord, value, fill=category)) \n",
    "p <- p + geom_boxplot(outlier.shape = 1, outlier.size = .5)\n",
    "p <- p + coord_flip() \n",
    "p <- p + labs(title=\"Distribuzione della difficoltà dei quiz\", \n",
    "              x=\"Quiz\", y=\"Difficoltà\")\n",
    "ggsave(filename = 'quiz_difficulty.png', plot = p, width = 10, height = 10)\n",
    "rm(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![quiz_difficulty](quiz_difficulty.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quiz_discrimination <- get_par_df(dfit, par = \"discrimination\", table = quizzes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=10, repr.plot.height=10)\n",
    "p <- ggplot(quiz_discrimination, aes(ord, value, fill=category)) \n",
    "p <- p + geom_boxplot(outlier.shape = 1, outlier.size = .5)\n",
    "p <- p + coord_flip() \n",
    "p <- p + labs(title=\"Distribuzione della differenziazione dei quiz\", \n",
    "              x=\"Quiz\", y=\"Differenziazione\")\n",
    "ggsave(filename = 'quiz_discrimination.png', plot = p, width = 10, height = 10)\n",
    "rm(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![quiz_discrimination](quiz_discrimination.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quiz_guessing <- get_par_df(dfit, par = \"guessing\", table = quizzes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  I singoli quesiti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
